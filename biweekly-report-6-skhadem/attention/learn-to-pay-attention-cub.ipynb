{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "deep-learning",
   "display_name": "deep-learning"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torchvision\n",
    "import torchvision.utils as utils\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import ImageStat\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from attn_vgg import AttnVGG\n",
    "from cub2011 import Cub2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_size = 64\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((im_size, im_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((im_size, im_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "])\n",
    "\n",
    "train_set = Cub2011(root='../../data', train=True, download=False, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=16, shuffle=True, num_workers=0)\n",
    "test_set = Cub2011(root='../../data', train=False, download=False, transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=16, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(img):\n",
    "  imagenet_stats = np.array([[0.5071, 0.4867, 0.4408], [0.2675, 0.2565, 0.2761]])\n",
    "  return img*imagenet_stats[1] + imagenet_stats[0]\n",
    "\n",
    "def show_image(img):\n",
    "  img = img.numpy().transpose(1,2,0)\n",
    "  img= denormalize(img)\n",
    "  plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"250.618594pt\" version=\"1.1\" viewBox=\"0 0 251.565 250.618594\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2020-11-16T08:33:42.154707</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.1, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 250.618594 \r\nL 251.565 250.618594 \r\nL 251.565 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 26.925 226.740469 \r\nL 244.365 226.740469 \r\nL 244.365 9.300469 \r\nL 26.925 9.300469 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p90a4123142)\">\r\n    <image height=\"218\" id=\"image2bc0cdd1a5\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAANoAAADaCAYAAADAHVzbAAAoXElEQVR4nO1d2a4lyVWNk5lnvlPNVV1d7dntCYzB0AiQGG0ExhJGwvDEgz/AfBmPSEggkMGWABmQjU3Tbrqr2u2qds3DHc6UJ5OHsjPWWnkiOu/p22GQ9nqKW5knMjIyo3LtHWvv3fv61/+ydj/BSy990CF6LvPtXs/xQfi7brpw62pNp62ryrfXFR3DHnuZ/yuTa9G1a8eQYYXG2+v5e9H+4/35f6jhPrHtnHNVxfcWAvfBv6kqOCY3mueFb2f+XnQ+KuhTx0h/4yG5ZzxUy31hHz0YB41JUMk4+HLhgeAz1D5ovrX/wO/qNb+b9CzknQjdj86Ho2vxsR+9/VbTDs+OwWA4M9hCMxgSoPi1X/vN5o+XX/55OpgBnSuygo71ityf58Kfz9Vq1bSXqzI8kBz6k8820dFKuSOMCcabZzkdq+F3WcH9Z0iRM6YQTAn9scVySectV/7vopC5gnZZ+jlQepLDHOSt+YYxQo+r5YLHsVy5EJbwLCqYUx0vjkNBFLxAOs73gve5WPBcYe91Fqbx+B603yvfv1LkAmg23mcl1BGfrVJHpPVruNa6lHcYfpf3+3ToypXXm7Z90QyGBLCFZjAkgC00gyEBiuPjWfPHw4eP6SBy3/F4RMem052m3QeOX7dsKL+Wi5w5bEVbAbjmhbdX6GJnrr6GMa5m3haYz9l2QZsqE7tgOPL31vqfB+yE4XDo/1m3D8Cu0W2Mk5OTpo33POoP6bzJdNy0c7Xz8sAWh7qhcxhvf0CH1vDD+dG8aZdiu4yGfj4m8twHAxgzzGP7uW/eFnGO35cZPKfDo0M679nTIz+mMd/L3t6eH5PYRmgvr9dgE/fY9sQ5znLxC8Dv8Fn3B3wttNHWMo9oY9oXzWBIAFtoBkMCFP2B/ySPhCbg519dwEgb8BOpigbmOUypSnCvzoBeLRfsQkXXbiXKE1Yx+L+W4n5fLLxrezhkGtIfoptXXf+bodQRXcU6xn7fz9269PRltpzTecvSj3Ey5T6G8JxwvntCHQe5PCfAGChyDfS2FJc1/n0y4zHW9E706QgCZ2coFBnnB89TCtgf+Hubz0/oWNbz15tMxnTsyVNvAq1Lf5/jMZ/H9JbfzQVsmwwKP/fDMd8LKkUWsrWS50YdDYaksIVmMCSALTSDIQGKJXDRw8MjPggyq+l0SsfQHppDH4sFu9VRLpQV7F6tqs2SLJVPZSjaER4/APsHbRC2H0SKo65osDdVhV+BLbMufR9Hx8d03vGJ3yZZyNYCSp9qsFNHI+b7Ozt+y0TnEf8u4J77Mh8rsk3ZjkTbDqVaK5HGlZU/lovNh3Y12roDmW+U3qniHSV1ZQnPQuzenZ1d6IOf2VOww3T8q5U/dwD2Idq5zvFzkR0ZNxrCVkuO0j6ej+Uato1k+wC3eeyLZjAkgC00gyEBihLcn+qYx51zdSOrC7vpQzo5PvEUS1XhO7uejg76nvbhzr5zvOOuionpwP8u7/v+y3V4K6G1g1/5eyvXTENmQAkRSu1m8LfsELidnUnTxi2U6WRC5/WBpp3M+Lpz6B+nWO8FaetaKBtuSSDdUrqM6gd1uVeheRRahqxVnxm9OmA+kIkgndSZjBHocy6Ko14P3wP/Lj16/IzOm4ISZ293j44R68bID3mH8Vm0dsBwC8wZDIb3HbbQDIYEKA72/SfzxevX6GAJXraZKASWlf8kD0C8Ohgo1fBeH6WfGEyKihIU4T6/tqdRqurId/3neZypsgWuBd/1QryaKwzGFGpwcO6gaaMYVukWevE0NwV6tzAIslwyTR1OcR75PimzRiRYcgSe16rkMaLHE9U2PbECMBC2lD5wJJhTRgQTrg9eyJXQ8XLlL4j0M5aHRY/t7Oz78Yq3rwQ6WpZ+HOVKKTLMsfSxWPj3/ekT740fy43uw/pBb7BzzvVhXdgXzWBIAFtoBkMC2EIzGBKgQHtIlSHoUr5//yEdK0FpfunihaZ94cIFOm8fAvR0+wDdz2g3Hezv03lod6xEIY224xxsOVWhoH2ofTw79AGHqsrfA3UCqmPaCXj875Zio6FKAs1UVajg35qgqD/w18PAzL4oMrDHUhMIgS3aB1tXlRvk+le7Ce6tqn17LpEIuM8z0yBcTNYD3WtALl5abWK06TMn0R5wDFVGwyHPFT9DzaPpfzcaoS1Hp9E73I+kPrUvmsGQALbQDIYEKFCUmoukYTryO+eDq1fpGOZUoDwKQjVW4MKeSw5CFOaiyxqv65x84ouw4gPZxVroIVJHze+HYlOlhCugyMczT7PX4vZ+fPikaQ+kD8zdwdSU+zg6xhwZkqsDxLG3b7/dtN+6eYvO+8XP/4q/ltBPUoZgwKLkXcTcKBoQWQOlKopw/kfcGlJaNoT3BZ+75lpBEbemmqdthlxF6BCIDO+jBrjifWveSNxeGQJVV3qLWxUna1bzYPCxfdEMhgSwhWYwJIAtNIMhAQp0KT96wnkdnz7zaueB5AgcQtDipOdV6Meidkc1/GzGNtqDx4+aNm4zaEDk1cuXm/YuBEc6x+5bVHQ/OeQcgSiROjjg7YPpjnfbqwSLXfPw/5K4ci/BtkahfUBioNnCz08rnyJKyGSbAd373/j7v23ar736Op33gQ9+pGmran4QUOXrFkEBdki5YvtqTYl1IC+ilsIC+y3XWgc9tKH8v2tCJUxuo9I+nP9KbTuwP0nuVamNBnUhxKYfDf3vMKdpr8dzin3WYrejnWpfNIMhAWyhGQwJUGAq5H2hVOOxp4RaYqiAXfYM1fCtqkrhnBDXrl1p2vM55KkQF+p44j/dmubaBZTsGimAruPd3V061u+HcyEit1mVmOuCqQa6g5WKYR6PncpfW93jlBtSJvLhvbtN+83v/5f/9/tP6Ly33vJVJq+/eCM4xgEoQzRHCwbeziXANRTQOZDgyz7Q57JVNdS30V0+EOUGK/YlBTu01TWPP8MtgqrmLRNUCD0TVRTSURyHKlQwMFgpMv7OvmgGQwLYQjMYEqDAT6F6qfZBoaGfTMxpcXzsvZMr2X3vAz2iSiTOuVCh8OGYU9v1gZZo0GYPq4AADTl37pxcKkxhg+c5rgSJzCAvhMpg5RDpHpUnWNGlJzQ7o7R3fPDWG967+OT+vaa9O2Yv7PGzp017b/dTdAwFwrMZevhEVAy0WHOooJIIvbCau2QGdFnzyGCAZAbBv/2CzQJOBc9jxCnWFHB4LlV0kec+IIUKf3PmIFanlH6tdwfeD0nNhx5s+6IZDAlgC81gSABbaAZDAhQ52FCFcl0XdmsirUcOq2Wbeli1XhQT/T6qB0C1IO5xxFrsiRw4co/+35CARdi1X4prHlXdKzmGLtoeKBpa2x1g367EFY1qCqo8KlUmB1QJkwMp//Wb/9S00eYb77HLejb3ERGag7AqMZdjOCkObk+oXZ0F0qerMn4JyviBJFSixEPwfqg9iMoKTTSEgSb6XqHiBpU9+szw2j2n9lsgokNMNMzZ2S5Z5mFfNIMhAWyhGQwJUCBNwGoszgk1cJJGewo5/ZzfBtA01Dm6QyNudVZJ6Pr3n+R1pSJXyMkIaaN1HJjCeykBqKge0M8/p8CGPmtx70d2DNCPjzRNK8E4EFM/ecw5Wn5061bT3jvweVgOj1jETRUup5Lnst78RyYBv2hOaBWXco3U2t/0SN6dHuTbzCLPcwEqlMWcaTvSPhUc44SrkggpJ/5O858gDW5pojW/90/70GpDsAXRCoS1nCEGQ1rYQjMYEsAWmsGQACTBWqjtUmHQnOS9A1cpukZVIsV8X120vg/kxGruYFBeqFyUc84VlFCF7R9MCFNVXC4JtyBUioM2Fdpyug2Ayn6nFUXBJkEbUO0A/PvunR/RseXcB8bugUtZg2lz6H8idpM+w58ia804JLQR2zyHYE9U/bfmDe17cdujrYTzq7K2ovA2a9Hn9wolUgu13+A2UWal8025IWUKcLsJ+1tJICzOnSZ9Wlvgp8GQFrbQDIYEKDD4TatMqmIAUaEyGWiDuqzxmBYAQuqBLmZ1tWLeSHU3o7oCr1VohdJIAGrsf5sK1fv9MA0ZqnKGgNsT4fOwLNQ7b79Nx4ZAo05OPG1S0oeUR58nmglEl7VEKUIpFTwzpF7liqk0R0uEu8f3RVUo+LOJcLvJ2G8pafVVNGWyYvP7odD8lZhrBM2EnoRcrAJqm+d/W7F4gyEpbKEZDAlgC81gSICCo1jVPQkJSkSahLwY1dKad3EIvDsvNEc62gkxDZOHupEpahbzrLdy/WFiHb5PdEW3y9ai1Af4vijvY+MPW7qMBZQ3euvmG3RsMgWXPthomljn+g2fkEcjfuel/x2VAhb7pMCIdnGrlzXaJPB+tKRxWDopHNlc4TzKOPBnWSWRDpijcsD3ie8j3qdGgVPUiUbWYxlitKvFnsV8p1ofIIf5ty+awZAAttAMhgQoMKfhQFzz6xw+/0KV0FU6B8qjn+dV6Y9VNX/iMyyRCGp4/YyTAlvc46hEURrFF3NwHt8Ll36KuemhD60oGqGOPbi3HvxM1eTHc5/k6PAJpzTHPImP17BdIMG6117w5bV0jEWF6hhI1HPCQaZzCB6lIE3H2zCortfATxq7vldrfK8w+JKBrvmWmr4CF77MfUAA45YL3oJYryAxlZTrRBaLvzs85i0TXAfjEc8VVyU1GAzvO2yhGQwJUCDdGkheveUaPVOiyAAKgbv0KiCNIttMG9pF1DGgM+wxXDgQH6/Du/SFqld6SEPCFBkDBdXLRj9T5Qn8Xbkw5UHhsFux2gG9qAMYx8H+AZ03nfqg0JWoNXCu0BQYKuWZ1xt/45xzNRW798eOoXqrc0z1lPbhbaNXU+eUg24l8BgVRzKPSGPRk3t4yGNEj/t0wkLzNRx7DFWV7t7ngFysvHP50qXg+O2LZjAkgC00gyEBbKEZDAlQoIt5LRoGLMXTa6k6Nq/RobiD0fpS1QXmYEeXu4g6yH5THo/QvX0EliJSBf0K+H8r9yTZJDDGMqwYLyQvZQ0ubEzwo+N49bvfadrzIy4jtCihfBSMY3/Iind0pbc0LpRjE6tpcq2DKahQ1DZCAwuVPfv7u3JeOOc9lX6CcbQS3wSiDZyLl1LiUk0QgCr2PY5LA1XweY6HPoAWg251/FgZ1DleC/ZFMxgSwBaawZAARd6L7b6HaRoWPUeaVkjlR3R7Z6LcwN4lbJCAyo3VivNDIPXFT7VSWNzGWEnRcKQeWnYKc4Fg2SbNGYJbEnkezkHI7nKe39e+/13fhwQYInGaLaCkkFJ1ODEWZIon6pYJ8qhWnhek1kQBJf04BX7Ke0R5WAJ5M90G2sojCR7BIWNZqP29PTqPq4aK4QHP82Df/+78+QO5FlB6eTdxe8W+aAZDAthCMxgSwBaawZAARQn2irrOUX18csTylRkkfsGkKqOR8HGi2VLOqPT23FL4LWIMEi9VgmNOP2yr/Ag5eF8lQTAuPYaRA/MllHdaqZ0XtieyVjDpT8a7YCX4ndt3/W9ki6DAaa28VOv8pSt03mwO85jxHNA2Cf17FjwPFfTOOddbo70MQZUSTEslrsR+o/5jCXNQgiU2VLVG178kYqJoDLCxZU4x0U7LFsVtDAzglOEult5e1mRIS7PRDIa0sIVmMCRAgXRR3bzo7p+IuhlzgfQCKvznx/xablNTqMK5DDv4MS9DK6cHUApUamt/WWQHn9J+q4sZ3M+YJ0XVCEiBVMWAwbWohrl38zad9+z+/aY9kpTmWBJoOvVU+sWXXqLzFpH06WuKrABq1KpeCvk46nD1VaTP7fkIKzfqQM7HFqVHSljLtgtcWyNL8D0mCijbS7StI6YG012YU8lrgr9btegzqmgMBsP7DltoBkMCFDV83mI78eqx6Y8C4lWhdvj5rISWYYDeUMSxCPpcr1vqzwZYlBwpmo5DqRJ7z8JFyaOpyeG+tTrlbO69UaPa3+cPvvfvdF7ugA6tefwVuG/Pnb/QtD/0sY/ReVp5E4HUNyQwdo7p82LB94LncrCuUCr0AIvaZgE5OJalP293yuJmNFe0f/ToqSIYzRVKbSd9PANPunqROZcO5KURDyqOQ+cK59G+aAZDAthCMxgSwBaawZAABVWxVDUFuElbLlQss5SF7R9k8rr7johxaYS6aAvsnwpDRfIsyjHk3bWYiuipRxtnuWB7djj0nH4k2wekVACb5P5truqJyZE0sHYNt33u4sWmvXdwjs7LaDslrHbAe1a7owZXupZEKktQfETsUrRXej3uH5913QM7RsaBtt18vgweU+Ac4DaP2qLLJW7XiJ0XSDVfS5wJRnHozhOqkeyLZjAkgC00gyEBippEl+xSHg2AAmUi6qxQkAkqAKnrScda1UIC1To1ABWg4tWnh0/9teDfp1LVBlNqt3KXZGHaivQLx1iuOY12Ufo+p7tMHfFqP7zl1SD3bt/hMeJ95xzQiYLpi1dfaNrzBY/DzSEotM99aHrvn0K3dWIKGKzbWtebn59CzY7RyCtbuhZz17QjSNlWqgLCSrLwrEcjtgtwS0lzhiDlPAHBu+YtLYCOFjHxtDMYDO87bKEZDAlgC81gSACKJ2y538PFGAkx9f4qEhCJgXdoC7QrcoardSKXRtmV3ssC7BB1I6P9pm7jcrU5qgBtC+e4wuXJyQkdw+u9feuWv5YECu6c89KqpeMxDmGOb3zoQ01bq3qiMaNBshgBgM9Ty11VAbtU/8b+tRQWbhksxPXPWzloT4WrqGZTcc2T9ElybMJLPRh4GddAS23BnM7m/JxPZvwM/W9k2wXVgWu+T0wqZV80gyEBbKEZDAlQUGCmHMRPvhb8xjwT6IbF3XbnnJtBMOZIFfoB6qEll9R9i9jd9W58SoetJZGW4ZTgjnJMiAKmROWC73M4ZFc5KrVbLnHgabdef7Vp54VWqvT33Rd66/p+7q6+4N37O7u8jUFBrEKzZzPZCvgJNDJjBCmw86mOEXJ4FmF1yXDsx1u28qvg+xLOFYNUcjjkLZOLF/wxTGHunHNLUKXglonSfTJX+vzcJ2OMHECzg6k6qk1UeXJ06Es82RfNYEgAW2gGQwIUSIE0aLCrWgM9gaoC6IFHSz2S5N0CqqfXwv61KHkfA0vx2pE8FTpG9NSp94yqYVJaM7lPujZ3j4d2gOYMhA7t7PjAx5MF3yeeO4YASaUrlH5c7pNzr8BPVGQNJXRaxeIDqfNieUE0f4vmZQn1ndN7wPcyBm8izptzzi3Ag6hpukNQFQ2aF5iDZCGmUR+o5EQo7LMn/pnZF81gSABbaAZDAthCMxgSgIyhmApA3eUUREi9SBIf4L6llDqipDiRxEDI3fNCgxQ3p3WO22GiEEA7LxIs2XPh/vF3qqJ5+NDnazx+dK9pf+bTL9N59x88atqrY3bFH4Abf2fXV9dUZQgpfQoeCCacQXe8mkwl2DW6XdOHrYAKYyPl+S0hUHMpdjXOP20LRORHuu2ChrA+T9yGyUF5EnvHNDoAt7NymOOlvMPrOrKtg2MKHjEYDGcGW2gGQwIUVUTRgH+3qoVkm13deh7RT3Ejo9g2C7npnXMFViVt3UK4Kin1keEOfh48b7mUNNowB3lgvM5JYfAh9//0gaeBqxMvJL53xKLi+RyKnAtVunT5WtPGbRitBFMFxvvTszei5nuuyvA7ga55FpOLaYGqDtkioPdqjdWMZIuA2kLV4U8NxkRlEVag1T40NycCTRSkppmYLmj+KP3Ey9kXzWBIAFtoBkMC2EIzGBKgQFtA3Z+9SF5+lEIhP++JJKggu0aCA4P2m9iKsahTABXFFDsvJwItUp9AMKNzHFSI9uZAFO/I6Qvh8Wjn3X3kkwnlku8wA6mPyuEuXLrctNG2qJ3YV3DfOgekBYtItbDKp1RLYrsGplHlUwXkq88qfu4lBuHCsbrWrRWI6NB3AP9uuebhWcA4enIv6x6MQ58FbBHgazuo2EuAt63TjW+kfdEMhgSwhWYwJECBLs/WzjnQC1XNrxabgzG1XBJ+T6PqEqCYSnmqiPIe3ezaPwLHvxZ3MFLCN37wKh375j/8XdP+vT/4ctO+9uINOm8OpZmWkmvxP//93/y1V36Ox1PJM9j3dHEh5akmoAzBPCz6zGIuay7SjvMmiiCg/5pfhQh4QMmvyJXGY+mnCPXCPCzlUngf/K4YhN85ooDyfuQuvF2zJqUP5raRYfTC3yq8HfuiGQwJYAvNYEiAAj2B+mlt5dZAwO9i+TiqClI+99Vjg5/kCMXE37TSmhVwHpzZ43EcHj9u2t/61j/RsR/813827Te+z9TxAgTz/dWPfQrv2+A9dM65Y0hNXlVMcz76wotNe2fs02ErLVsDlalrDlj8zn98u2mfu3ylaV+CtnOc/2MhAZff/Y6vMHrl8tWmff0G02DqT8aYkWICvNJKWeuwABv/rtZhL2mUBsO1VUVTgTqpR8xalEnYh6hGMFcMmhqtMeJ1teop5ptxBoPhfYctNIMhAWyhGQwJUGSxap1gKw0keUk/x3JPmOmFeTAGG6orFNNto/tdbTnOKRm233CropJU5JOJD5b87d/6Ah37n+99t2kP5P+enam3qUZwsQsSbHh+31fePJqzKr8H9zmExDrjEc/pEmyN1Yr5/n/887/69r94W+uDH/4AnfcLv/xLTftNSD/unHOzYz+uL/3xV/11F2wPohmyFpXLoPbPBqu+rmSbgewVzZUJEQBLLIkk+R9RdtFKfU7jDW8HoeqnlZs027zN4BwnhFrAGGPBnasVzwHm0bQvmsGQALbQDIYEKCiFdEtUjJ9dphD5AEW04fx7+Hlu5fNDUSqKkYUK6CeZgGmeUYTaUkz4diGBiC++6N3vi/v36NhHXvBi3v/54dtNuyyZbvXAra4FaBbg5l0twzSkBLrb77Nq5PLeftN+cM9vJczuPaHz8iN/7OLBRTr2ud//jaY9BqXJfC4F4SP0CClWThVQRRCM74HwshVQxNk8nJ9kACbEBLZFnGMlUUudAZejIFM+i9Uf8t6i8JnzlnIfXAWJH/wS7tO+aAZDAthCMxgSwBaawZAABfLl+YztDpKoRHKroyJdly7adq3MfO1IOeeccwtRai/moIYXvj9GmQtcq5WfEf8QN+9HX/5k0/72N/+Rjq16Xqr0C5/9dNN+cPcunffo8WHTLsXWwAQ6z6DKpyrG0a6pa+4Dn9P1S95eyzj+1L3+xhtN+9f/8CvcP9izJzAOzY2PLvcsY7c6btcM0T5WaRKq8sW9v0LXOcyV2tVOtpQQGSVb4jHitKIdtlqFbaie+gXWKMHyv2vnlwxLBwuMgtAbMBgMZw9baAZDAhRIqlopwSFoTnPnLSHwE1XiWswdqyzqRxc/tfiZXYlCYA79K91agKoBD+kXHvN4DEumJJdeeKlpf+nP/4KPXfIu8nMHe0373s0f0Hk/fvO1pn3jyTM6dnh43LSfPPMU8/iEA0SPIWB0teB5HA79PL78CU91dw7O03nXPuqPTQ8u0DF0WaNrPpM8L6PMB6COxpy7ZAy5TAaQX0XpIeb4UMpGKg8M6nUM7L8vaiEsJ6U5WijXCGyZtOKCKd27HAKl0mKB2wD8bha5H4fm0cRx2RfNYEgAW2gGQwIUmL9hMFTvDX6CRS0wwHRc/hNZiucIAwe1Ege6ptA72Rto6i8/Ls1dMgPvGaWvE7UAeotWQm+HY6+S+Nznf5WO9QPUd/c8B1zuXfYF3F/91t/TsauXLzXt42NPHY8OD+m8+0/838+OWZj82V//7ab9ym/+btPuiYKkJGGyiHQBrNjRZxYO1i2gGiiZGpHgTi3SPhr5d2k08VRUU4JjULLSsj6msxOTB0eCQuVWQXuYOqWVOCdLoL4qYMb3W6nv00dW8dNgSApbaAZDAthCMxgSoIilkM4wpbGo90fgbh4MwnkX0cWpNsMaygUV1D8TZkqAIvbEzsQHUqKbWt210WqP8LtCXN24BVESb2d7YnLg7bA7dx/QsUOwfS9dPGja5yDNt/599WM/T8c+/Iuv+HFAqU3NUTkAG6ovthFVR8XgzlJUNJjzMZK7MYu45kklkXMf+JxysLV0iwDHm8tzwW0eHeIac4nS9pXY/nSf3AfaXhydwqCcoxJsnJsyxGBIC1toBkMCUOBnK90xFt3OlFLBZxFUAD2tykGVWoRCQCURUny0t/BhxPwZJxdtoAqpc7wtoMJQpEd5LLdlRElw57YPCn3nHlPHBQRZ4hSromG671Ue1z/xGTpWw1YIVfKR8eI81pojA/vDf5dni1SylVsRTkWiFEvHrpVgOFU2Pnf5HeR8XPfkmcG7uRZzBQOMq0hFlzWmw192C3atZYxYAUdzWyKttC+awZAAttAMhgSwhWYwJECB0qe+BNDFgusomUkVkOU4R77XnpDwItucN18TpfB1Gd0yPuq4quAxdWcjP0dneT4WOQ+40udzDqBdjr01c3QCgY5iFF/6sA8sHe/u0zGk//1AwKxzztVw39p/HxPaUL5D7m8JCet1O4Vz8EDQrbrwI+W00GQjm0cDYbOQVcm2Vyu3f8ekTxXm1xfXPG0foDxQt54yfG/DsC+awZAAttAMhgQoqOpmodQxTPtCigGlfazIDpM76k/rgpNCRbYZkHJSEXWlGgDpo3Lha2M3VOxe3M03X/1e0+6LimG59LTkcH3StIcTDqr8wMc/CX9peSoch6eprdyQwO2UYRJdhHtRlzWINdxK6RaV1worcXoR6hjaCdD/9WsqqyTHIvSZxgWdVmv9zeZ8M85FTJLWlgnyVFFWYbr94GgNBsOZwRaawZAABXqL8iJMy3RJZoFPpqpL8GNaq/IkC7TbRASuFVYgYB91xef10XMUU0y0KpZuJhEatPngHa8MGY04GBM9Whgke/E85/u4cv1601bnLSlz8D7lwRQVqiK0D/SehYHvgXoTqRA7qoMilKp2OqfUYWQk8BtVfwSKuT/vcXOfOqdYBakSYXUVEExL7Ch5J6ta6b7lDDEYksIWmsGQALbQDIYEKIZDn5duZzoKnqicPgtW4Qxz7kqPhQTTwvezqEUB9mHkLHa1Sn+0tRBO+Yz3effOTTprvfDJdMaTCR07gfyNKyj3dONDH6Hzrr1w1YUQnm8F2suRLQ7su/Uv3RQZWUfbWeeUSymhwijShdjOZKNFXP0MtfPC166opJNHyxaN3Pdk4teWfdEMhgSwhWYwJEAxnXhX9Ln9SeRUFeluPqafVkS7EgccC1GS5/8QHEeb6m1GbFzbYCRBrHtAuy/u7dKxH/74YdNeLLyo+NOf5eDO8+d8/pNI0U1BZE6jnXScD/2veItxtVQdwWcWVqEoUOWhJklIPh4zQdpmTUhl1P09msA2j33RDIYEsIVmMCSALTSDIQGKPiSIGYt0iDhzi5puTqqyrSUUtbSiFBkzp3Sz17SL+K/qjc27kIzHOedOoBzT6MIlOnbpwCfnWRdedvWRj3+czkPJjkp9wsPrHm4YNK9q/TNcxTLoSo8Mo2X/hE6O2WQ6+OL0Lv2YyRoLNg71p9D+c1PvGwxpYQvNYEiAIpKyQWjDe3eP6+c5rC2JufdbnUIn3RQqeqibzoKrRz545x06b136Mw8Pj+hYCZziwpVrTfvgAqv32S0dozKYDptHryp36j+SezHYR63PbLOdEKNeWesQBnTG7AIM+A33EaWctPXUbU712lXkPNyq0DHidNsXzWBIAFtoBkMC2EIzGBIgXI/GOXcWdhn39t7767Vodjd5jMbgRq4QPLJYevnUs0cP6dhoPG7amgsezDd37fqNpj0chqMl4gD7IXYrXW9TTWLN1gNAe6W7aj5iewXtte1RhT4fneVjZw/7ohkMCWALzWBIAKGOXalXd1IZYSFB4UmLaEQZRegCEqBHyVZOow3x567LcKrsnamnjidLrsI5g8DPy9euNO2Wu73eTKmcE1rVmWFFJr8OTP7zgcGFz4DOdZ3urSMFIr+LRX505tbvfQ7si2YwJIAtNIMhAQra6I8wjW39hW0v4WZ0ZYdtGgkCWMolqH1EqECM38KhJ08eN+3lfEan7U990ObaLehYfeLP3dk/gAOnoSSB8cfYUGvyT5/nRY+RlzD2wkQKycf63wqaYwbobjSPTEePZ7gOUXfYF81gSABbaAZDAthCMxgSoDijzfgGbYU+Sbz53LMIDgA7IeaxPovbfHj/ftN+/OgpHSun3qVf53069sINrwb52CdeDvbfmf+TKlxDLqC/s9gG6L6R0/VikT5jNuUp+qeAy272WhxbjsPU+wZDWthCMxgS4F1ExadHTDgc9aJ3jNPsqhqptcM60H4XrJarpv3Nb3yjaef9AZ1XUdFwHuVvfOGLTfvg4FzwWrH/9YKVjiJzGgv0jAWIEjqn0VQKG0v13fHaUb9611yLm2nk8y5Pnyck09Th+NwjXN2+aAZDAthCMxgSwBaawZAAZKMpbe+Yy6UztvbgR/h42PEadnufRvr04P7dpn3ztf9u2hd3Ob/+AhT6F65foWOf+gzk2I9KwcLj2EYG1NkOi0Feggz6rLqaSR1toWjEQucUSu86mFMjOt9daz+cyUgMBkMUttAMhgTgxMpnTBVPgzhJeJ85bB2++m1I/X30zOdrnPR5Z6QP7v7f+sMv0bGdvT282Mbm80ufPr35qehh5xQfsb2QzWmuowWiWmnFuw0KXelxutw1J+N2IJV/KzdkNymOfdEMhgSwhWYwJEDxs6SLiLMYRtSx2KsCZzJUFP32m7eadpH5Ei+DnR0673d+/4+a9qd+7rPhQXb21HXDqdQf22hj5byuVIwE3mciXD9j9fuWaCtDOv7u7IdiMBgUttAMhgSwhWYwJAD7qN9naYimkFa3b6c+5O9uWR2dq+turvNKyjbeuXOnafdHPoX3F7/8FTrv87/yStPOssh9bTmlIc+x2mFks0UT98SuFu4DvdtVx3tpl3Ta/ENV00e/AjghOt+hvI5b542MbBeYMsRg+L8DW2gGQwIU5Ho9A6oYJQmqEECG8t4Lk8T7iwaWhu97urfftP/sa19r2p9/5RU6L8uwuruKhbf0pSO2eTSRHJjdO49NeNcuwqnPY4hV2uz6ieiuLuk4kGjl0cg4tr22wWDoDltoBkMC2EIzGBKA1fvCnTmZTjjgssu/bzzW1b7aAu3kPN0Miizj/3v+5Kt/2rR3prtwXiQAtZ34v9OJ3b3N205WZ3/8qX8Su9LW8adnkfR+S9BWQ+fPkan3DYafKWyhGQwJUMRTPcTczVtwis5q8m7lgJ7/LKD42JZ/yn3t7e4HTtRhnbFrPoYIpY/jvXNCZnDhe44+zq0ezWlSgvtmPN9HpAvcFjiDz5F90QyGBLCFZjAkAHkdTyP6RaFoNA04dahHN3PHNknoms87ko/jrN1nZxGHGEvlFvtdR0qvQaFb1X1X0TL2F9Npb8FSz6pWfNAmSey5RNgXzWBIAFtoBkMC2EIzGBKAAj9PFYgZ4uBK1mNLOWR6qWu+azboWF2owE/etf+tDJv3js4lnM4CXYNAnXOu3nz19rsDNve20hC6lPbfLdkS4RRG4DYu/V5ELWRfNIMhAWyhGQwJ8C4VP2OffKh0GKMGvH8QOa2j6zwWzBgNYkXVSKz/WBWayO+i53W7t+7F4sMX26qCTCt3Y8cbhWu184J0wzZVN3Uc0T6ikxruAxlyL/I5ilX5xEdhXzSDIQFsoRkMCWALzWBIgOJv/uavmz9ef/21n+FQfnboanpt3d//s9zz0RjZ4DBiaZnCx9g2P82T2OapRcYR1ZBth5s332za9kUzGBLAFprBkAD/C0kHn7ydoAktAAAAAElFTkSuQmCC\" y=\"-8.740469\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mf9fba9875e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"28.62375\" xlink:href=\"#mf9fba9875e\" y=\"226.740469\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(25.4425 241.338906)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.59875\" xlink:href=\"#mf9fba9875e\" y=\"226.740469\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(56.23625 241.338906)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"96.57375\" xlink:href=\"#mf9fba9875e\" y=\"226.740469\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(90.21125 241.338906)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"130.54875\" xlink:href=\"#mf9fba9875e\" y=\"226.740469\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 30 -->\r\n      <g transform=\"translate(124.18625 241.338906)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"164.52375\" xlink:href=\"#mf9fba9875e\" y=\"226.740469\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 40 -->\r\n      <g transform=\"translate(158.16125 241.338906)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"198.49875\" xlink:href=\"#mf9fba9875e\" y=\"226.740469\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(192.13625 241.338906)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"232.47375\" xlink:href=\"#mf9fba9875e\" y=\"226.740469\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 60 -->\r\n      <g transform=\"translate(226.11125 241.338906)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_8\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m49b63ca7c2\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m49b63ca7c2\" y=\"10.999219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(13.5625 14.798437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m49b63ca7c2\" y=\"44.974219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(7.2 48.773437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m49b63ca7c2\" y=\"78.949219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(7.2 82.748437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m49b63ca7c2\" y=\"112.924219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 30 -->\r\n      <g transform=\"translate(7.2 116.723437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m49b63ca7c2\" y=\"146.899219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 40 -->\r\n      <g transform=\"translate(7.2 150.698437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m49b63ca7c2\" y=\"180.874219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(7.2 184.673437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m49b63ca7c2\" y=\"214.849219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 60 -->\r\n      <g transform=\"translate(7.2 218.648437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 26.925 226.740469 \r\nL 26.925 9.300469 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 244.365 226.740469 \r\nL 244.365 9.300469 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 26.925 226.740469 \r\nL 244.365 226.740469 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 26.925 9.300469 \r\nL 244.365 9.300469 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p90a4123142\">\r\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"9.300469\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "show_image(next(iter(train_set))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "conv_block1.op.0.weight\nconv_block1.op.0.bias\nconv_block1.op.1.weight\nconv_block1.op.1.bias\nconv_block1.op.1.running_mean\nconv_block1.op.1.running_var\nconv_block1.op.1.num_batches_tracked\nconv_block1.op.3.weight\nconv_block1.op.3.bias\nconv_block1.op.4.weight\nconv_block1.op.4.bias\nconv_block1.op.4.running_mean\nconv_block1.op.4.running_var\nconv_block1.op.4.num_batches_tracked\nconv_block2.op.0.weight\nconv_block2.op.0.bias\nconv_block2.op.1.weight\nconv_block2.op.1.bias\nconv_block2.op.1.running_mean\nconv_block2.op.1.running_var\nconv_block2.op.1.num_batches_tracked\nconv_block2.op.3.weight\nconv_block2.op.3.bias\nconv_block2.op.4.weight\nconv_block2.op.4.bias\nconv_block2.op.4.running_mean\nconv_block2.op.4.running_var\nconv_block2.op.4.num_batches_tracked\nconv_block3.op.0.weight\nconv_block3.op.0.bias\nconv_block3.op.1.weight\nconv_block3.op.1.bias\nconv_block3.op.1.running_mean\nconv_block3.op.1.running_var\nconv_block3.op.1.num_batches_tracked\nconv_block3.op.3.weight\nconv_block3.op.3.bias\nconv_block3.op.4.weight\nconv_block3.op.4.bias\nconv_block3.op.4.running_mean\nconv_block3.op.4.running_var\nconv_block3.op.4.num_batches_tracked\nconv_block3.op.6.weight\nconv_block3.op.6.bias\nconv_block3.op.7.weight\nconv_block3.op.7.bias\nconv_block3.op.7.running_mean\nconv_block3.op.7.running_var\nconv_block3.op.7.num_batches_tracked\nconv_block4.op.0.weight\nconv_block4.op.0.bias\nconv_block4.op.1.weight\nconv_block4.op.1.bias\nconv_block4.op.1.running_mean\nconv_block4.op.1.running_var\nconv_block4.op.1.num_batches_tracked\nconv_block4.op.3.weight\nconv_block4.op.3.bias\nconv_block4.op.4.weight\nconv_block4.op.4.bias\nconv_block4.op.4.running_mean\nconv_block4.op.4.running_var\nconv_block4.op.4.num_batches_tracked\nconv_block4.op.6.weight\nconv_block4.op.6.bias\nconv_block4.op.7.weight\nconv_block4.op.7.bias\nconv_block4.op.7.running_mean\nconv_block4.op.7.running_var\nconv_block4.op.7.num_batches_tracked\nconv_block5.op.0.weight\nconv_block5.op.0.bias\nconv_block5.op.1.weight\nconv_block5.op.1.bias\nconv_block5.op.1.running_mean\nconv_block5.op.1.running_var\nconv_block5.op.1.num_batches_tracked\nconv_block5.op.3.weight\nconv_block5.op.3.bias\nconv_block5.op.4.weight\nconv_block5.op.4.bias\nconv_block5.op.4.running_mean\nconv_block5.op.4.running_var\nconv_block5.op.4.num_batches_tracked\nconv_block5.op.6.weight\nconv_block5.op.6.bias\nconv_block5.op.7.weight\nconv_block5.op.7.bias\nconv_block5.op.7.running_mean\nconv_block5.op.7.running_var\nconv_block5.op.7.num_batches_tracked\nconv_block6.op.0.weight\nconv_block6.op.0.bias\nconv_block6.op.1.weight\nconv_block6.op.1.bias\nconv_block6.op.1.running_mean\nconv_block6.op.1.running_var\nconv_block6.op.1.num_batches_tracked\nconv_block6.op.4.weight\nconv_block6.op.4.bias\nconv_block6.op.5.weight\nconv_block6.op.5.bias\nconv_block6.op.5.running_mean\nconv_block6.op.5.running_var\nconv_block6.op.5.num_batches_tracked\ndense.weight\ndense.bias\nprojector.op.weight\nattn1.op.weight\nattn2.op.weight\nattn3.op.weight\nclassify.weight\nclassify.bias\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('./checkpoints/attn-net_epoch_90.pth')\n",
    "pretrained_dict = checkpoint['model_state_dict']\n",
    "for k,v in pretrained_dict.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_layer_name(filter_names, layer_name):\n",
    "    for name in filter_names:\n",
    "        if name in layer_name:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempt = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['dense.weight', 'dense.bias', 'classify.weight', 'classify.bias'], unexpected_keys=[])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "model = AttnVGG(im_size=im_size, num_classes=200, normalize_attn=False)\n",
    "\n",
    "# Load the last CIFAR-100 checkpoint. Note we filter out the layers that have different dimensions\n",
    "filter_names = ['dense', 'classify']#, 'attn', 'projector']\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if filter_layer_name(filter_names, k)}\n",
    "\n",
    "model.load_state_dict(pretrained_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Freezing conv_block1.op.0.weight\nFreezing conv_block1.op.0.bias\nFreezing conv_block1.op.1.weight\nFreezing conv_block1.op.1.bias\nFreezing conv_block1.op.3.weight\nFreezing conv_block1.op.3.bias\nFreezing conv_block1.op.4.weight\nFreezing conv_block1.op.4.bias\nFreezing conv_block2.op.0.weight\nFreezing conv_block2.op.0.bias\nFreezing conv_block2.op.1.weight\nFreezing conv_block2.op.1.bias\nFreezing conv_block2.op.3.weight\nFreezing conv_block2.op.3.bias\nFreezing conv_block2.op.4.weight\nFreezing conv_block2.op.4.bias\nFreezing conv_block3.op.0.weight\nFreezing conv_block3.op.0.bias\nFreezing conv_block3.op.1.weight\nFreezing conv_block3.op.1.bias\nFreezing conv_block3.op.3.weight\nFreezing conv_block3.op.3.bias\nFreezing conv_block3.op.4.weight\nFreezing conv_block3.op.4.bias\nFreezing conv_block3.op.6.weight\nFreezing conv_block3.op.6.bias\nFreezing conv_block3.op.7.weight\nFreezing conv_block3.op.7.bias\nFreezing conv_block4.op.0.weight\nFreezing conv_block4.op.0.bias\nFreezing conv_block4.op.1.weight\nFreezing conv_block4.op.1.bias\nFreezing conv_block4.op.3.weight\nFreezing conv_block4.op.3.bias\nFreezing conv_block4.op.4.weight\nFreezing conv_block4.op.4.bias\nFreezing conv_block4.op.6.weight\nFreezing conv_block4.op.6.bias\nFreezing conv_block4.op.7.weight\nFreezing conv_block4.op.7.bias\nFreezing conv_block5.op.0.weight\nFreezing conv_block5.op.0.bias\nFreezing conv_block5.op.1.weight\nFreezing conv_block5.op.1.bias\nFreezing conv_block5.op.3.weight\nFreezing conv_block5.op.3.bias\nFreezing conv_block5.op.4.weight\nFreezing conv_block5.op.4.bias\nFreezing conv_block5.op.6.weight\nFreezing conv_block5.op.6.bias\nFreezing conv_block5.op.7.weight\nFreezing conv_block5.op.7.bias\nFreezing conv_block6.op.0.weight\nFreezing conv_block6.op.0.bias\nFreezing conv_block6.op.1.weight\nFreezing conv_block6.op.1.bias\nFreezing conv_block6.op.4.weight\nFreezing conv_block6.op.4.bias\nFreezing conv_block6.op.5.weight\nFreezing conv_block6.op.5.bias\nFreezing projector.op.weight\nFreezing attn1.op.weight\nFreezing attn2.op.weight\nFreezing attn3.op.weight\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if filter_layer_name(filter_names, name):\n",
    "    # if filter_layer_name(filter_names + ['attn', 'projector'], name):\n",
    "        param.requires_grad = False\n",
    "        print('Freezing ' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "# lr_lambda = lambda epoch : np.power(0.5, int(epoch/15))\n",
    "# scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[4, 7, 10, 50], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "epoch 0 learning rate 0.100000\n",
      "\n",
      "[epoch 0][0/374] loss 5.2668 accuracy 6.25%\n",
      "[epoch 0][30/374] loss 6.3583 accuracy 0.00%\n",
      "[epoch 0][60/374] loss 5.8377 accuracy 6.25%\n",
      "[epoch 0][90/374] loss 5.6528 accuracy 6.25%\n",
      "[epoch 0][120/374] loss 5.5305 accuracy 12.50%\n",
      "[epoch 0][150/374] loss 5.6840 accuracy 0.00%\n",
      "[epoch 0][180/374] loss 4.7885 accuracy 12.50%\n",
      "[epoch 0][210/374] loss 5.5203 accuracy 12.50%\n",
      "[epoch 0][240/374] loss 5.2836 accuracy 0.00%\n",
      "[epoch 0][270/374] loss 4.9981 accuracy 6.25%\n",
      "[epoch 0][300/374] loss 5.0814 accuracy 0.00%\n",
      "[epoch 0][330/374] loss 4.8059 accuracy 0.00%\n",
      "[epoch 0][360/374] loss 5.1638 accuracy 6.25%\n",
      "----------------------------------------\n",
      "\n",
      "[epoch 0] accuracy on test data: 4.38%\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "epoch 1 learning rate 0.100000\n",
      "\n",
      "[epoch 1][0/374] loss 4.4417 accuracy 18.75%\n",
      "[epoch 1][30/374] loss 5.0997 accuracy 18.75%\n",
      "[epoch 1][60/374] loss 5.1637 accuracy 12.50%\n",
      "[epoch 1][90/374] loss 5.6225 accuracy 0.00%\n",
      "[epoch 1][120/374] loss 4.4496 accuracy 12.50%\n",
      "[epoch 1][150/374] loss 5.4957 accuracy 0.00%\n",
      "[epoch 1][180/374] loss 5.3264 accuracy 0.00%\n",
      "[epoch 1][210/374] loss 4.5326 accuracy 6.25%\n",
      "[epoch 1][240/374] loss 5.0367 accuracy 0.00%\n",
      "[epoch 1][270/374] loss 4.9393 accuracy 6.25%\n",
      "[epoch 1][300/374] loss 4.4776 accuracy 12.50%\n",
      "[epoch 1][330/374] loss 4.7740 accuracy 6.25%\n",
      "[epoch 1][360/374] loss 4.6746 accuracy 12.50%\n",
      "----------------------------------------\n",
      "\n",
      "[epoch 1] accuracy on test data: 5.13%\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "epoch 2 learning rate 0.100000\n",
      "\n",
      "[epoch 2][0/374] loss 4.2529 accuracy 12.50%\n",
      "[epoch 2][30/374] loss 4.8503 accuracy 6.25%\n",
      "[epoch 2][60/374] loss 4.7635 accuracy 6.25%\n",
      "[epoch 2][90/374] loss 4.4876 accuracy 25.00%\n",
      "[epoch 2][120/374] loss 4.2340 accuracy 18.75%\n",
      "[epoch 2][150/374] loss 4.9293 accuracy 12.50%\n",
      "[epoch 2][180/374] loss 4.0543 accuracy 12.50%\n",
      "[epoch 2][210/374] loss 4.7299 accuracy 18.75%\n",
      "[epoch 2][240/374] loss 4.3321 accuracy 37.50%\n",
      "[epoch 2][270/374] loss 4.4609 accuracy 12.50%\n",
      "[epoch 2][300/374] loss 4.1912 accuracy 18.75%\n",
      "[epoch 2][330/374] loss 5.1816 accuracy 0.00%\n",
      "[epoch 2][360/374] loss 4.1673 accuracy 18.75%\n",
      "----------------------------------------\n",
      "\n",
      "[epoch 2] accuracy on test data: 6.92%\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "epoch 3 learning rate 0.010000\n",
      "\n",
      "[epoch 3][0/374] loss 4.6175 accuracy 6.25%\n",
      "[epoch 3][30/374] loss 4.0383 accuracy 6.25%\n",
      "[epoch 3][60/374] loss 3.9901 accuracy 12.50%\n",
      "[epoch 3][90/374] loss 4.5108 accuracy 6.25%\n",
      "[epoch 3][120/374] loss 3.7122 accuracy 18.75%\n",
      "[epoch 3][150/374] loss 3.3042 accuracy 31.25%\n",
      "[epoch 3][180/374] loss 4.1387 accuracy 31.25%\n",
      "[epoch 3][210/374] loss 4.1888 accuracy 12.50%\n",
      "[epoch 3][240/374] loss 4.0705 accuracy 31.25%\n",
      "[epoch 3][270/374] loss 3.9238 accuracy 18.75%\n",
      "[epoch 3][300/374] loss 3.3945 accuracy 37.50%\n",
      "[epoch 3][330/374] loss 3.6804 accuracy 18.75%\n",
      "[epoch 3][360/374] loss 3.7167 accuracy 12.50%\n",
      "----------------------------------------\n",
      "\n",
      "[epoch 3] accuracy on test data: 9.04%\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "epoch 4 learning rate 0.010000\n",
      "\n",
      "[epoch 4][0/374] loss 3.8320 accuracy 25.00%\n",
      "[epoch 4][30/374] loss 3.8527 accuracy 18.75%\n",
      "[epoch 4][60/374] loss 3.0669 accuracy 37.50%\n",
      "[epoch 4][90/374] loss 4.0230 accuracy 18.75%\n",
      "[epoch 4][120/374] loss 4.2048 accuracy 25.00%\n",
      "[epoch 4][150/374] loss 4.4323 accuracy 18.75%\n",
      "[epoch 4][180/374] loss 3.7075 accuracy 18.75%\n",
      "[epoch 4][210/374] loss 3.7163 accuracy 18.75%\n",
      "[epoch 4][240/374] loss 3.7208 accuracy 31.25%\n",
      "[epoch 4][270/374] loss 4.0740 accuracy 12.50%\n",
      "[epoch 4][300/374] loss 3.0327 accuracy 50.00%\n",
      "[epoch 4][330/374] loss 3.9402 accuracy 12.50%\n",
      "[epoch 4][360/374] loss 3.8692 accuracy 25.00%\n",
      "----------------------------------------\n",
      "\n",
      "[epoch 4] accuracy on test data: 8.75%\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "epoch 5 learning rate 0.010000\n",
      "\n",
      "[epoch 5][0/374] loss 3.8702 accuracy 18.75%\n",
      "[epoch 5][30/374] loss 4.2927 accuracy 18.75%\n",
      "[epoch 5][60/374] loss 3.3528 accuracy 50.00%\n",
      "[epoch 5][90/374] loss 3.9167 accuracy 12.50%\n",
      "[epoch 5][120/374] loss 3.5952 accuracy 18.75%\n",
      "[epoch 5][150/374] loss 3.6138 accuracy 25.00%\n",
      "[epoch 5][180/374] loss 3.4452 accuracy 18.75%\n",
      "[epoch 5][210/374] loss 3.8502 accuracy 18.75%\n",
      "[epoch 5][240/374] loss 4.2492 accuracy 12.50%\n",
      "[epoch 5][270/374] loss 3.4504 accuracy 43.75%\n",
      "[epoch 5][300/374] loss 3.9544 accuracy 37.50%\n",
      "[epoch 5][330/374] loss 3.9999 accuracy 25.00%\n",
      "[epoch 5][360/374] loss 3.5098 accuracy 25.00%\n",
      "----------------------------------------\n",
      "\n",
      "[epoch 5] accuracy on test data: 8.77%\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "epoch 6 learning rate 0.001000\n",
      "\n",
      "[epoch 6][0/374] loss 3.0169 accuracy 25.00%\n",
      "[epoch 6][30/374] loss 3.4554 accuracy 25.00%\n",
      "[epoch 6][60/374] loss 3.4023 accuracy 37.50%\n",
      "[epoch 6][90/374] loss 3.9257 accuracy 25.00%\n",
      "[epoch 6][120/374] loss 3.2448 accuracy 43.75%\n",
      "[epoch 6][150/374] loss 3.9642 accuracy 18.75%\n",
      "[epoch 6][180/374] loss 3.6823 accuracy 25.00%\n",
      "[epoch 6][210/374] loss 3.6821 accuracy 25.00%\n",
      "[epoch 6][240/374] loss 3.3175 accuracy 50.00%\n",
      "[epoch 6][270/374] loss 3.3164 accuracy 31.25%\n",
      "[epoch 6][300/374] loss 3.6586 accuracy 25.00%\n",
      "[epoch 6][330/374] loss 3.6841 accuracy 31.25%\n",
      "[epoch 6][360/374] loss 3.8262 accuracy 25.00%\n",
      "----------------------------------------\n",
      "\n",
      "[epoch 6] accuracy on test data: 9.15%\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "epoch 7 learning rate 0.001000\n",
      "\n",
      "[epoch 7][0/374] loss 2.9023 accuracy 25.00%\n",
      "[epoch 7][30/374] loss 4.1811 accuracy 37.50%\n",
      "[epoch 7][60/374] loss 3.6048 accuracy 31.25%\n",
      "[epoch 7][90/374] loss 3.6758 accuracy 37.50%\n",
      "[epoch 7][120/374] loss 3.4267 accuracy 25.00%\n",
      "[epoch 7][150/374] loss 3.1464 accuracy 37.50%\n",
      "[epoch 7][180/374] loss 3.8907 accuracy 18.75%\n",
      "[epoch 7][210/374] loss 3.9612 accuracy 31.25%\n",
      "[epoch 7][240/374] loss 3.1956 accuracy 37.50%\n",
      "[epoch 7][270/374] loss 3.3507 accuracy 37.50%\n",
      "[epoch 7][300/374] loss 3.4125 accuracy 31.25%\n",
      "[epoch 7][330/374] loss 3.8759 accuracy 25.00%\n",
      "[epoch 7][360/374] loss 3.4829 accuracy 12.50%\n",
      "----------------------------------------\n",
      "\n",
      "[epoch 7] accuracy on test data: 9.51%\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "epoch 8 learning rate 0.001000\n",
      "\n",
      "[epoch 8][0/374] loss 3.5720 accuracy 37.50%\n",
      "[epoch 8][30/374] loss 3.2959 accuracy 31.25%\n",
      "[epoch 8][60/374] loss 2.9794 accuracy 50.00%\n",
      "[epoch 8][90/374] loss 3.5970 accuracy 25.00%\n",
      "[epoch 8][120/374] loss 3.8580 accuracy 25.00%\n",
      "[epoch 8][150/374] loss 4.0817 accuracy 12.50%\n",
      "[epoch 8][180/374] loss 3.3865 accuracy 31.25%\n",
      "[epoch 8][210/374] loss 3.7900 accuracy 43.75%\n",
      "[epoch 8][240/374] loss 3.8164 accuracy 18.75%\n",
      "[epoch 8][270/374] loss 3.4059 accuracy 37.50%\n",
      "[epoch 8][300/374] loss 3.4598 accuracy 31.25%\n",
      "[epoch 8][330/374] loss 3.8834 accuracy 25.00%\n",
      "[epoch 8][360/374] loss 3.0362 accuracy 43.75%\n",
      "----------------------------------------\n",
      "\n",
      "[epoch 8] accuracy on test data: 9.67%\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "epoch 9 learning rate 0.000100\n",
      "\n",
      "[epoch 9][0/374] loss 3.9063 accuracy 18.75%\n",
      "[epoch 9][30/374] loss 4.3666 accuracy 6.25%\n",
      "[epoch 9][60/374] loss 3.7802 accuracy 31.25%\n",
      "[epoch 9][90/374] loss 3.4840 accuracy 18.75%\n",
      "[epoch 9][120/374] loss 3.4928 accuracy 37.50%\n",
      "[epoch 9][150/374] loss 3.5944 accuracy 31.25%\n",
      "[epoch 9][180/374] loss 3.6622 accuracy 12.50%\n",
      "[epoch 9][210/374] loss 3.4698 accuracy 25.00%\n",
      "[epoch 9][240/374] loss 3.2772 accuracy 37.50%\n",
      "[epoch 9][270/374] loss 3.5575 accuracy 43.75%\n",
      "[epoch 9][300/374] loss 3.2089 accuracy 31.25%\n",
      "[epoch 9][330/374] loss 3.3486 accuracy 37.50%\n",
      "[epoch 9][360/374] loss 3.8594 accuracy 12.50%\n",
      "----------------------------------------\n",
      "\n",
      "[epoch 9] accuracy on test data: 9.49%\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "epoch 10 learning rate 0.000100\n",
      "\n",
      "[epoch 10][0/374] loss 3.4017 accuracy 31.25%\n",
      "[epoch 10][30/374] loss 3.7963 accuracy 31.25%\n",
      "[epoch 10][60/374] loss 3.7922 accuracy 18.75%\n",
      "[epoch 10][90/374] loss 3.4663 accuracy 31.25%\n",
      "[epoch 10][120/374] loss 3.7783 accuracy 25.00%\n",
      "[epoch 10][150/374] loss 3.6168 accuracy 25.00%\n",
      "[epoch 10][180/374] loss 3.4968 accuracy 25.00%\n",
      "[epoch 10][210/374] loss 3.6016 accuracy 12.50%\n",
      "[epoch 10][240/374] loss 3.2795 accuracy 50.00%\n",
      "[epoch 10][270/374] loss 3.5656 accuracy 25.00%\n",
      "[epoch 10][300/374] loss 4.1721 accuracy 12.50%\n",
      "[epoch 10][330/374] loss 3.4833 accuracy 25.00%\n",
      "[epoch 10][360/374] loss 2.9872 accuracy 37.50%\n",
      "----------------------------------------\n",
      "\n",
      "[epoch 10] accuracy on test data: 9.54%\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "epoch 11 learning rate 0.000100\n",
      "\n",
      "[epoch 11][0/374] loss 3.4752 accuracy 18.75%\n",
      "[epoch 11][30/374] loss 3.9932 accuracy 25.00%\n",
      "[epoch 11][60/374] loss 3.5613 accuracy 25.00%\n",
      "[epoch 11][90/374] loss 4.3434 accuracy 18.75%\n",
      "[epoch 11][120/374] loss 3.9600 accuracy 37.50%\n",
      "[epoch 11][150/374] loss 4.1025 accuracy 18.75%\n",
      "[epoch 11][180/374] loss 3.9347 accuracy 18.75%\n",
      "[epoch 11][210/374] loss 3.1544 accuracy 25.00%\n",
      "[epoch 11][240/374] loss 3.2517 accuracy 50.00%\n",
      "[epoch 11][270/374] loss 3.6033 accuracy 25.00%\n",
      "[epoch 11][300/374] loss 3.8117 accuracy 18.75%\n",
      "[epoch 11][330/374] loss 3.1518 accuracy 43.75%\n",
      "[epoch 11][360/374] loss 3.6970 accuracy 31.25%\n",
      "----------------------------------------\n",
      "\n",
      "[epoch 11] accuracy on test data: 9.39%\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "epoch 12 learning rate 0.000100\n",
      "\n",
      "[epoch 12][0/374] loss 3.7662 accuracy 25.00%\n",
      "[epoch 12][30/374] loss 3.5047 accuracy 37.50%\n",
      "[epoch 12][60/374] loss 3.9148 accuracy 18.75%\n",
      "[epoch 12][90/374] loss 3.4198 accuracy 37.50%\n",
      "[epoch 12][120/374] loss 3.5070 accuracy 31.25%\n",
      "[epoch 12][150/374] loss 4.3328 accuracy 12.50%\n",
      "[epoch 12][180/374] loss 3.7421 accuracy 25.00%\n",
      "[epoch 12][210/374] loss 4.0276 accuracy 18.75%\n",
      "[epoch 12][240/374] loss 3.8250 accuracy 12.50%\n",
      "[epoch 12][270/374] loss 3.7381 accuracy 6.25%\n",
      "[epoch 12][300/374] loss 3.4048 accuracy 37.50%\n",
      "[epoch 12][330/374] loss 3.3003 accuracy 37.50%\n",
      "[epoch 12][360/374] loss 3.6847 accuracy 18.75%\n",
      "----------------------------------------\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-3d80e98e4a50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;31m# log scalars\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m             \u001b[0mimages_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mimages_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep-learning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep-learning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep-learning\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep-learning\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\School\\Fall2020\\applied-deep-learning\\biweekly-report-6-skhadem\\attention\\cub2011.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m  \u001b[1;31m# Targets start at 1 by default, so shift to 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep-learning\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep-learning\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep-learning\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2885\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2887\u001b[1;33m     \u001b[0mprefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2889\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# attempt += 1\n",
    "step = 0\n",
    "log_freq = 30\n",
    "epochs = 100\n",
    "save_freq = 10\n",
    "run_name = 'cub_pretrained_attempt_%s'%attempt\n",
    "checkpoints_folder = './checkpoints/%s/'%run_name\n",
    "if not os.path.isdir(checkpoints_folder):\n",
    "    os.mkdir(checkpoints_folder)\n",
    "writer = SummaryWriter('./runs/' + run_name)\n",
    "for epoch in range(epochs + 1):\n",
    "    # adjust learning rate\n",
    "    scheduler.step()\n",
    "    writer.add_scalar('train/learning_rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "    print(\"\\nepoch %d learning rate %f\\n\" % (epoch, optimizer.param_groups[0]['lr']))\n",
    "    # run for one epoch\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # warm up\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        pred, _, _, _ = model(inputs)\n",
    "\n",
    "        # backward\n",
    "        loss = criterion(pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # display results\n",
    "        if i % log_freq == 0:\n",
    "            model.eval()\n",
    "            pred, __, __, __ = model(inputs)\n",
    "            predict = torch.argmax(pred, 1)\n",
    "            total = labels.size(0)\n",
    "            correct = torch.eq(predict, labels).sum().double().item()\n",
    "            accuracy = correct / total\n",
    "            writer.add_scalar('train/loss', loss.item(), step)\n",
    "            writer.add_scalar('train/accuracy', accuracy, step)\n",
    "\n",
    "            print(\"[epoch %d][%d/%d] loss %.4f accuracy %.2f%%\"\n",
    "                % (epoch, i, len(train_loader)-1, loss.item(), (100*accuracy)))\n",
    "        \n",
    "        step += 1\n",
    "\n",
    "    if epoch % save_freq == 0:\n",
    "        torch.save(\n",
    "            {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "            }, \n",
    "            '%s/cub_attn-net_epoch_%s.pth' % (checkpoints_folder, epoch)\n",
    "        )\n",
    "\n",
    "    print('-'*40)\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        # log scalars\n",
    "        for i, data in enumerate(test_loader):\n",
    "            images_test, labels_test = data\n",
    "            images_test, labels_test = images_test.cuda(), labels_test.cuda()\n",
    "            pred_test, _, _, _ = model(images_test)\n",
    "            predict = torch.argmax(pred_test, 1)\n",
    "            total += labels_test.size(0)\n",
    "            correct += torch.eq(predict, labels_test).sum().double().item()\n",
    "        writer.add_scalar('test/accuracy', correct/total, epoch)\n",
    "        print(\"\\n[epoch %d] accuracy on test data: %.2f%%\\n\" % (epoch, 100*correct/total))\n",
    "    \n",
    "    print('-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}